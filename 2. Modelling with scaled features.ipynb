{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "raw = pd.read_csv('OnlineNewsPopularity/OnlineNewsPopularity.csv')\n",
    "raw.columns = [c.strip() for c in raw.columns]\n",
    "raw.drop(columns=['url', 'timedelta'], inplace=True)\n",
    "raw['popular'] = raw['shares'].apply(lambda row: 0 if row < 1400 else 1)\n",
    "raw.drop(columns=['shares'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw.drop(columns=['popular'])\n",
    "y = raw['popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['data_channel_is_lifestyle', 'data_channel_is_bus',\n",
    "               'data_channel_is_entertainment', 'data_channel_is_socmed',\n",
    "               'data_channel_is_tech', 'data_channel_is_world', 'weekday_is_monday', \n",
    "               'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday',\n",
    "               'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_cat = X_train[cat_vars]\n",
    "X_train_cont = X_train.drop(columns=cat_vars, axis=1)\n",
    "X_train_cont[X_train_cont.columns] = scaler.fit_transform(X_train_cont)\n",
    "X_train_scaled = pd.concat([X_train_cat, X_train_cont], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat = X_test[cat_vars]\n",
    "X_test_cont = X_test.drop(columns=cat_vars, axis=1)\n",
    "X_test_cont[X_test_cont.columns] = scaler.fit_transform(X_test_cont)\n",
    "X_test_scaled = pd.concat([X_test_cat, X_test_cont], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6548680006726081"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function to separate categorical and continuous data, scale continuous data, and return joined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_scale_combine(X, cat_vars):\n",
    "    X_cat = X[cat_vars]\n",
    "    X_cont = X.drop(columns=cat_vars, axis=1)\n",
    "\n",
    "    X_cont[X_cont.columns] = scaler.fit_transform(X_cont)\n",
    "    X_scaled = pd.concat([X_cat, X_cont], axis=1)\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving window run with previously optimized hyperparameters and then again with newly optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_min = 0\n",
    "index_max = 10000\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=30, min_samples_leaf=1)\n",
    "rf_predictions = pd.DataFrame(columns=['y_actual', 'y_predict'], dtype=int)\n",
    "\n",
    "while index_max <= 39000:\n",
    "    X_train_rf = X.iloc[index_min : index_max]\n",
    "    X_train_rf_scaled = sep_scale_combine(X_train_rf, cat_vars)\n",
    "    y_train_rf = y.iloc[index_min : index_max]\n",
    "    \n",
    "    X_test_rf = X.iloc[index_max : (index_max + 1000)]\n",
    "    X_test_rf_scaled = sep_scale_combine(X_test_rf, cat_vars)\n",
    "    y_test_rf = y.iloc[index_max : (index_max + 1000)]\n",
    "    \n",
    "    rf.fit(X_train_rf_scaled, y_train_rf)\n",
    "    y_predictions_rf = rf.predict(X_test_rf_scaled)\n",
    "    y_actual_and_predict_rf = pd.DataFrame({'y_actual': y_test_rf, 'y_predict': y_predictions_rf})\n",
    "    rf_predictions = rf_predictions.append(y_actual_and_predict_rf, ignore_index=False)\n",
    "    index_min += 1000\n",
    "    index_max += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6540952637970584"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(rf_predictions['y_actual'].values, rf_predictions['y_predict'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'min_samples_leaf': 1, 'n_estimators': 1000}\n",
      "0.6787455860097528\n"
     ]
    }
   ],
   "source": [
    "X_scaled = sep_scale_combine(X, cat_vars)\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(X_scaled, y, test_size=0.3, random_state=15)\n",
    "\n",
    "rf_scaled = RandomForestClassifier()\n",
    "rf_params_scaled = {'n_estimators': [200, 400, 750, 1000], 'max_depth' : [15, 20, 30], 'min_samples_leaf' : [1, 5, 10]}\n",
    "gsRf_scaled = GridSearchCV(estimator=rf_scaled, param_grid=rf_params_scaled)\n",
    "\n",
    "gsRf_scaled.fit(X_train_scaled, y_train_scaled)\n",
    "print(gsRf_scaled.best_params_ )\n",
    "gsRf_scaled.predict(X_test_scaled)\n",
    "print(gsRf_scaled.score(X_test_scaled, y_test_scaled)) # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data has an accuracy of 68% while testing data has an accuracy of 65%. Does not generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
